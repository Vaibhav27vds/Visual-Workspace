{
  "version": 3,
  "sources": ["../../../../src/cli/lib/indexes.ts"],
  "sourcesContent": ["import { AxiosResponse } from \"axios\";\nimport chalk from \"chalk\";\nimport path from \"path\";\nimport { bundleSchema } from \"../../bundler/index.js\";\nimport { version } from \"../version.js\";\nimport {\n  Context,\n  changeSpinner,\n  logFailure,\n  logFinishedStep,\n  logError,\n} from \"../../bundler/context.js\";\nimport {\n  poll,\n  logAndHandleAxiosError,\n  deprecationCheckWarning,\n  deploymentClient,\n} from \"./utils.js\";\n\ntype IndexMetadata = {\n  table: string;\n  name: string;\n  fields:\n    | string[]\n    | {\n        searchField: string;\n        filterFields: string[];\n      };\n  backfill: {\n    state: \"in_progress\" | \"done\";\n  };\n};\n\ntype SchemaState =\n  | { state: \"pending\" }\n  | { state: \"validated\" }\n  | { state: \"active\" }\n  | { state: \"overwritten\" }\n  | { state: \"failed\"; error: string; tableName?: string };\n\ntype SchemaStateResponse = {\n  indexes: IndexMetadata[];\n  schemaState: SchemaState;\n};\ntype PrepareSchemaResponse = {\n  added: IndexMetadata[];\n  dropped: IndexMetadata[];\n  schemaId: string;\n};\n\nexport async function pushSchema(\n  ctx: Context,\n  origin: string,\n  adminKey: string,\n  schemaDir: string,\n  dryRun: boolean\n): Promise<{ schemaId?: string; schemaState?: SchemaState }> {\n  if (!ctx.fs.exists(path.resolve(schemaDir, \"schema.ts\"))) {\n    // Don't do anything.\n    return {};\n  }\n  const bundles = await bundleSchema(ctx, schemaDir);\n\n  changeSpinner(ctx, \"Checking for index or schema changes...\");\n\n  let data: PrepareSchemaResponse;\n  const client = deploymentClient(origin);\n  try {\n    const res = await client.post<PrepareSchemaResponse>(\n      \"/api/prepare_schema\",\n      {\n        bundle: bundles[0],\n        adminKey,\n        dryRun,\n      },\n      {\n        headers: {\n          \"Convex-Client\": `npm-cli-${version}`,\n        },\n      }\n    );\n    deprecationCheckWarning(ctx, res);\n    data = res.data;\n  } catch (err) {\n    logFailure(ctx, `Error: Unable to run schema validation on ${origin}`);\n    return await logAndHandleAxiosError(ctx, err);\n  }\n\n  const schemaId = data.schemaId;\n\n  changeSpinner(\n    ctx,\n    \"Backfilling indexes and checking that documents match your schema...\"\n  );\n  const schemaState = await waitForReadySchema(ctx, origin, adminKey, schemaId);\n  logIndexChanges(ctx, data, dryRun);\n  return { schemaId, schemaState };\n}\n\n/// Wait for indexes to build and schema to be validated.\nasync function waitForReadySchema(\n  ctx: Context,\n  origin: string,\n  adminKey: string,\n  schemaId: string\n): Promise<SchemaState> {\n  const path = `/api/schema_state/${schemaId}`;\n  const client = deploymentClient(origin);\n  const fetch = async () => {\n    try {\n      return await client.get<SchemaStateResponse>(path, {\n        headers: {\n          Authorization: `Convex ${adminKey}`,\n          \"Convex-Client\": `npm-cli-${version}`,\n        },\n        data: { schemaId },\n      });\n    } catch (err) {\n      logFailure(\n        ctx,\n        `Error: Unable to build indexes and run schema validation on ${origin}`\n      );\n      return await logAndHandleAxiosError(ctx, err);\n    }\n  };\n  const validate = (result: AxiosResponse<SchemaStateResponse, any>) =>\n    result.data.indexes.every((index) => index.backfill.state === \"done\") &&\n    result.data.schemaState.state !== \"pending\";\n  const result = await poll(fetch, validate);\n  switch (result.data.schemaState.state) {\n    case \"failed\":\n      // Schema validation failed. This could be either because the data\n      // is bad or the schema is wrong. Classify this as a filesystem error\n      // because adjusting `schema.ts` is the most normal next step.\n      logFailure(ctx, \"Schema validation failed\");\n      logError(ctx, chalk.red(`${result.data.schemaState.error}`));\n      return await ctx.crash(1, {\n        \"invalid filesystem or db data\":\n          result.data.schemaState.tableName ?? null,\n      });\n\n    case \"overwritten\":\n      logFailure(ctx, `Schema was overwritten by another push.`);\n      return await ctx.crash(1, \"fatal\");\n    case \"validated\":\n      logFinishedStep(ctx, \"Schema validation complete.\");\n      break;\n    case \"active\":\n      break;\n  }\n  return result.data.schemaState;\n}\n\nfunction logIndexChanges(\n  ctx: Context,\n  indexes: {\n    added: IndexMetadata[];\n    dropped: IndexMetadata[];\n  },\n  dryRun: boolean\n) {\n  if (indexes.dropped.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.dropped) {\n      indexDiff += `  [-] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      ctx,\n      `${dryRun ? \"Would delete\" : \"Deleted\"} table indexes:\\n${indexDiff}`\n    );\n  }\n  if (indexes.added.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.added) {\n      indexDiff += `  [+] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      ctx,\n      `${dryRun ? \"Would add\" : \"Added\"} table indexes:\\n${indexDiff}`\n    );\n  }\n}\n\nfunction stringifyIndex(index: IndexMetadata) {\n  return `${index.table}.${index.name} ${JSON.stringify(index.fields)}`;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AACA,mBAAkB;AAClB,kBAAiB;AACjB,qBAA6B;AAC7B,qBAAwB;AACxB,qBAMO;AACP,mBAKO;AAiCP,eAAsB,WACpB,KACA,QACA,UACA,WACA,QAC2D;AAC3D,MAAI,CAAC,IAAI,GAAG,OAAO,YAAAA,QAAK,QAAQ,WAAW,WAAW,CAAC,GAAG;AAExD,WAAO,CAAC;AAAA,EACV;AACA,QAAM,UAAU,UAAM,6BAAa,KAAK,SAAS;AAEjD,oCAAc,KAAK,yCAAyC;AAE5D,MAAI;AACJ,QAAM,aAAS,+BAAiB,MAAM;AACtC,MAAI;AACF,UAAM,MAAM,MAAM,OAAO;AAAA,MACvB;AAAA,MACA;AAAA,QACE,QAAQ,QAAQ,CAAC;AAAA,QACjB;AAAA,QACA;AAAA,MACF;AAAA,MACA;AAAA,QACE,SAAS;AAAA,UACP,iBAAiB,WAAW;AAAA,QAC9B;AAAA,MACF;AAAA,IACF;AACA,8CAAwB,KAAK,GAAG;AAChC,WAAO,IAAI;AAAA,EACb,SAAS,KAAP;AACA,mCAAW,KAAK,6CAA6C,QAAQ;AACrE,WAAO,UAAM,qCAAuB,KAAK,GAAG;AAAA,EAC9C;AAEA,QAAM,WAAW,KAAK;AAEtB;AAAA,IACE;AAAA,IACA;AAAA,EACF;AACA,QAAM,cAAc,MAAM,mBAAmB,KAAK,QAAQ,UAAU,QAAQ;AAC5E,kBAAgB,KAAK,MAAM,MAAM;AACjC,SAAO,EAAE,UAAU,YAAY;AACjC;AAGA,eAAe,mBACb,KACA,QACA,UACA,UACsB;AACtB,QAAMA,QAAO,qBAAqB;AAClC,QAAM,aAAS,+BAAiB,MAAM;AACtC,QAAM,QAAQ,YAAY;AACxB,QAAI;AACF,aAAO,MAAM,OAAO,IAAyBA,OAAM;AAAA,QACjD,SAAS;AAAA,UACP,eAAe,UAAU;AAAA,UACzB,iBAAiB,WAAW;AAAA,QAC9B;AAAA,QACA,MAAM,EAAE,SAAS;AAAA,MACnB,CAAC;AAAA,IACH,SAAS,KAAP;AACA;AAAA,QACE;AAAA,QACA,+DAA+D;AAAA,MACjE;AACA,aAAO,UAAM,qCAAuB,KAAK,GAAG;AAAA,IAC9C;AAAA,EACF;AACA,QAAM,WAAW,CAACC,YAChBA,QAAO,KAAK,QAAQ,MAAM,CAAC,UAAU,MAAM,SAAS,UAAU,MAAM,KACpEA,QAAO,KAAK,YAAY,UAAU;AACpC,QAAM,SAAS,UAAM,mBAAK,OAAO,QAAQ;AACzC,UAAQ,OAAO,KAAK,YAAY,OAAO;AAAA,IACrC,KAAK;AAIH,qCAAW,KAAK,0BAA0B;AAC1C,mCAAS,KAAK,aAAAC,QAAM,IAAI,GAAG,OAAO,KAAK,YAAY,OAAO,CAAC;AAC3D,aAAO,MAAM,IAAI,MAAM,GAAG;AAAA,QACxB,iCACE,OAAO,KAAK,YAAY,aAAa;AAAA,MACzC,CAAC;AAAA,IAEH,KAAK;AACH,qCAAW,KAAK,yCAAyC;AACzD,aAAO,MAAM,IAAI,MAAM,GAAG,OAAO;AAAA,IACnC,KAAK;AACH,0CAAgB,KAAK,6BAA6B;AAClD;AAAA,IACF,KAAK;AACH;AAAA,EACJ;AACA,SAAO,OAAO,KAAK;AACrB;AAEA,SAAS,gBACP,KACA,SAIA,QACA;AACA,MAAI,QAAQ,QAAQ,SAAS,GAAG;AAC9B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,SAAS;AACnC,mBAAa,SAAS,eAAe,KAAK;AAAA;AAAA,IAC5C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE;AAAA,MACA,GAAG,SAAS,iBAAiB;AAAA,EAA6B;AAAA,IAC5D;AAAA,EACF;AACA,MAAI,QAAQ,MAAM,SAAS,GAAG;AAC5B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,OAAO;AACjC,mBAAa,SAAS,eAAe,KAAK;AAAA;AAAA,IAC5C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE;AAAA,MACA,GAAG,SAAS,cAAc;AAAA,EAA2B;AAAA,IACvD;AAAA,EACF;AACF;AAEA,SAAS,eAAe,OAAsB;AAC5C,SAAO,GAAG,MAAM,SAAS,MAAM,QAAQ,KAAK,UAAU,MAAM,MAAM;AACpE;",
  "names": ["path", "result", "chalk"]
}
